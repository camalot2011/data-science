---
title: "Health Related Federal Grant Tracking"
---

The US government invests billions each year into the health research. The "open government" initiative provides more transparency into the governmental activities in the health related sector. Grant application data from NIH, ACF, AHRQ, CDC, HRSA, FDA, and VA are now easily accessible. With that large amount of data, we can now track the trend of the health research according to the amount of grant money. What research topics/areaes get more attractive? How have they been changing over the years? What area in the health sector will likely be the next breakthrough? I will try to explore those questions from the grant application database. And hopeful go even beyond.

First of all, the database called NIH ExPORTER is accesible [here](https://exporter.nih.gov/ExPORTER_Catalog.aspx). A total of 7.3 GB data were downloaded. 

```{r dependency, include=FALSE}
library(NLP);library(openNLP)                            # Natural language processing
library(stringi)                                         # string tools
library(tm)                                              # test mining
library(RWeka);library(RWekajars)
library(tidyverse)
library(data.table)
library(slam)
library(tidytext)
library(wordcloud)
```

Each grant application has to include a "Public Health Relevance" statement, a plain text explaining the relevance of the proposed reseach to the general audience. It provides the keywords that are interested to the public. This is the section I am going to focus on in the following study.

First of all, let's take a look at the data to see what we are going to get. In the databse, the key words for each application are included. Let's see what is the popular "terms" (in the project terms entry) in 2016 in the health research. Data are imported, cleaned, and tokenized. Then, a document-term matrix is generated. Since the key words are provided, I stick to the term frequency method. 
```{r import, include=FALSE}
#Set the working directory to the root of data folder before the following code
proj <- fread(paste0(getwd(),"/Data/PRJ/",list.files("./Data/PRJ")[32]))
proj <- proj %>% filter(!is.na(PHR),!is.na(PROJECT_TERMS))
```
```{r cleaning, include=FALSE}
cleaning <- function(text,words = words_remove) {
    corpus <- Corpus(VectorSource(text))
    corpus <- tm_map(corpus, tolower)
    corpus <- tm_map(corpus, removeWords, c(words_remove,stopwords("english")))
    corpus <- tm_map(corpus, removePunctuation)
    corpus <- tm_map(corpus, removeNumbers)
    corpus <- tm_map(corpus, stripWhitespace)
    return(corpus)
}
text <- proj$PROJECT_TERMS
words_remove <- c("research","cell","cells","health","human","disease")
corpus <- cleaning(text,words_remove)
```
```{r word_freq_PT, include=FALSE}
dtm <- DocumentTermMatrix(corpus)
dtm <- removeSparseTerms(dtm,0.99)
freq <- sort(colapply_simple_triplet_matrix(dtm,FUN = sum),decreasing = TRUE)
freq<- data.frame(word = attr(freq,"names"),freq = freq)
```
```{r PT_plot, echo=FALSE}
wordcloud(freq[,1],freq[,2],scale = c(2.8,0.2),max.words = 20,colors = brewer.pal(3,"Dark2"),use.r.layout = TRUE)
```


From the plot, we can see that "cancer" was a hightly mentioned topic in 2016, which is not that surprising given that cancer is the no.2 killer disease in US. Another trend we can get from this plot is the shift of the research focus into more clinical settings, as demonstrated by "therapeutic" and "clinical". This trend is consistent with the call of NIH for more translational research in [2008](https://www.nih.gov/news-events/news-releases/nih-expands-national-consortium-dedicated-transforming-clinical-translational-research).

Next, let's get into the "public health relevance (PHR)" sections. The PHR sections are included into the database since 2014. We will look the data from 2014 to 2017.
```{r PHR_loading,include=FALSE}
fns <- tail(list.files("./Data/PRJ"),4)
proj_PHR <- list()
for (i in seq_along(fns)) {
  temp <- fread(paste0(getwd(),"/Data/PRJ/",fns[i]))
  temp <- temp %>% 
            select(APPLICATION_ID,FY,PHR,TOTAL_COST,TOTAL_COST_SUB_PROJECT)
  temp[which(is.na(TOTAL_COST)),"TOTAL_COST"] <- 0
  temp[which(is.na(TOTAL_COST_SUB_PROJECT)),"TOTAL_COST_SUB_PROJECT"] <- 0
  temp <- temp %>% mutate(total = as.numeric(TOTAL_COST+TOTAL_COST_SUB_PROJECT)) %>%
                select(APPLICATION_ID,FY,PHR,total)
  proj_PHR[[i]] <- temp
}
names(proj_PHR) <-c("2014","2015","2016","2017")
```

I prepare the PHR text for analysis. Applications with empty PHR are removed. Some formating words are deleted, too.
```{r cleaning_PHR,include=FALSE}
words_remove <- c("project","narrative","public","health","relevance")
freq_total <- list()
for (i in seq_along(proj_PHR)) {
    proj_PHR[[i]] <- proj_PHR[[i]] %>% filter(nchar(PHR) != 0)
    text <- proj_PHR[[i]]$PHR
    corpus <- cleaning(text,words_remove)
    dtm <- DocumentTermMatrix(corpus,control = list(weighting = weightTfIdf))
    dtm <- removeSparseTerms(dtm,0.95)
    freq <- sort(colapply_simple_triplet_matrix(dtm,FUN = sum),decreasing = TRUE)
    freq<- data.frame(word = attr(freq,"names"),freq = freq)
    freq_total[[i]] <- freq
}
names(freq_total) <-c("freq2014","freq2015","freq2016","freq2017")
```

Let's take a look at the change of "cancer","gene",and "clinical" over those 4 years. 
```{r include=FALSE}
word_trend <- function(word) {
  word_data <- data.frame()  
  for (i in seq_along(freq_total)) {
      t <- data.frame(word = word, 
                      freq = freq_total[[i]]$freq[which(freq_total[[i]]$word == word)],
                      year = names(proj_PHR)[i])
      word_data <- rbind(word_data,t)
  }
  return(word_data)
}

cancer <- word_trend("cancer")
clinical <- word_trend("clinical")
gene <- word_trend("gene")
PHR_plot <- rbind(cancer,clinical,gene)
```
```{r echo=FALSE}
ggplot(PHR_plot,aes(year,freq,color = word)) + geom_bar(stat = "identity",position = "dodge",aes(fill = word))+ 
  labs(title = "Fig.2 Words appear over the years",x = "Year", y = "Frequency")
```


Since the sample size is small, the plot doesn't show much change. However, this idea can extend beyond. NIH starts to record the key words of the grant applicaitons since 2008. Those key words are stored in the "Publication Terms". We can now take a look at those entries.
```{r PT_loading,include=FALSE}
fns <- tail(list.files("./Data/PRJ"),10)
proj_PT <- list()
for (i in seq_along(fns)) {
  temp <- fread(paste0(getwd(),"/Data/PRJ/",fns[i]))
  temp <- temp %>% 
            select(APPLICATION_ID,FY,PROJECT_TERMS,TOTAL_COST,TOTAL_COST_SUB_PROJECT)
  temp[which(is.na(TOTAL_COST)),"TOTAL_COST"] <- 0
  temp[which(is.na(TOTAL_COST_SUB_PROJECT)),"TOTAL_COST_SUB_PROJECT"] <- 0
  temp <- temp %>% mutate(total = as.numeric(TOTAL_COST+TOTAL_COST_SUB_PROJECT)) %>%
                select(APPLICATION_ID,FY,PROJECT_TERMS,total)
  proj_PT[[i]] <- temp
}
names(proj_PT) <-as.character(c(2008:2017))
```
```{r cleaning_PT,include=FALSE}
words_remove <- c("research","cell","cells","health","human","disease")
freq_PT_total <- list()
for (i in seq_along(proj_PT)) {
    proj_PT[[i]] <- proj_PT[[i]] %>% filter(nchar(PROJECT_TERMS) != 0)
    text <- proj_PT[[i]]$PROJECT_TERMS
    corpus <- cleaning(text,words_remove)
    dtm <- DocumentTermMatrix(corpus)
    dtm <- removeSparseTerms(dtm,0.95)
    freq <- sort(colapply_simple_triplet_matrix(dtm,FUN = sum),decreasing = TRUE)
    freq<- data.frame(word = attr(freq,"names"),freq = freq)
    freq_PT_total[[i]] <- freq
}
names(freq_PT_total) <-as.character(c(2008:2017))
```
```{r include=FALSE}
word_trend_PT <- function(word) {
  word_data <- data.frame()  
  for (i in seq_along(freq_PT_total)) {
      t <- data.frame(word = word, 
                      freq = freq_PT_total[[i]]$freq[which(freq_PT_total[[i]]$word == word)],
                      year = names(proj_PT)[i])
      word_data <- rbind(word_data,t)
  }
  return(word_data)
}

cancer <- word_trend_PT("cancer")
clinical <- word_trend_PT("clinical")
gene <- word_trend_PT("gene")
PT_plot <- rbind(cancer,clinical,gene)
```
```{r echo=FALSE}
ggplot(PT_plot,aes(year,freq,color = word)) + geom_bar(stat = "identity",position = "dodge",aes(fill = word))+
  labs(title = "Fig.3 Words appear over the years by project terms",x = "Year", y = "Frequency")
```


Now this plot looks very interesting. The big jump from 2011 to 2012 might be due to the implementation of the new record system. Besides that hump, it appears that "clinical" has a down trend after the NIH announcement for the translational studies. It bounds back quickly after 2011 and surpass the other two key words. Cancer is rather steady over the past decade. Gene seems to get back to the track after 2015.

Now comes to the most interesting part. Let's look at the grant application abstracts. Abstracts will have much more words to dig through. 

```{r ABS_loading,include=FALSE}
fns <- list.files("./Data/PRJABS")
proj_ABS <- list()
for (i in seq_along(fns)) {
  temp <- fread(paste0(getwd(),"/Data/PRJABS/",fns[i]))
  temp <- temp %>% 
            select(APPLICATION_ID,ABSTRACT_TEXT)
  proj_ABS[[i]] <- temp
}
names(proj_ABS) <-as.character(c(1985:2017))
```
```{r cleaning_ABS,include=FALSE}
words_remove <- c("unreadable","cell","cells","health","human","disease")
freq_ABS_total <- list()
for (i in seq_along(proj_ABS)) {
    proj_ABS[[i]] <- proj_ABS[[i]] %>% filter(nchar(ABSTRACT_TEXT) != 0)
    text <- proj_ABS[[i]]$ABSTRACT_TEXT
    corpus <- cleaning(text,words_remove)
    dtm <- DocumentTermMatrix(corpus,control = list(weighting = weightTfIdf))
    dtm <- removeSparseTerms(dtm,0.95)
    freq <- sort(colapply_simple_triplet_matrix(dtm,FUN = sum),decreasing = TRUE)
    freq<- data.frame(word = attr(freq,"names"),freq = freq)
    freq_ABS_total[[i]] <- freq
}
names(freq_ABS_total) <-as.character(c(1985:2017))
```
```{r include=FALSE}
word_trend_ABS <- function(word) {
  word_data <- data.frame()  
  for (i in seq_along(freq_ABS_total)) {
      t <- data.frame(word = word, 
                      freq = freq_ABS_total[[i]]$freq[which(freq_ABS_total[[i]]$word == word)],
                      year = names(proj_ABS)[i])
      word_data <- rbind(word_data,t)
  }
  return(word_data)
}

cancer <- word_trend_ABS("cancer")
clinical <- word_trend_ABS("clinical")
gene <- word_trend_ABS("gene")
ABS_plot <- rbind(cancer,clinical,gene)
```
```{r echo=FALSE}
ggplot(ABS_plot,aes(year,freq,group = word,color = word)) + geom_line()+geom_point(aes(shape = word,size = 2))+theme(axis.text.x = element_text(size = 12))+scale_x_discrete(breaks = seq(1985,2017,4))+
  labs(title = "Fig.4 Words appear over the years by applicatoin abstracts",x = "Year", y = "Frequency")
```

Plot from this analysis reveals other trends. Cancer is always higher than the rest of two. Gene is in a down trend in recent years while the other two are in the up trend in general. However, the project can extend beyond. It will be interesting to see the trend of funding using this method to predict the next breakthrough in the health sector. Some of the parameters for text mining will need further refinement. Clustering/Classification can also be applied later on to get a better key word category. 
